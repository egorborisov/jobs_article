[
    {
        "client_msg_id": "b3559cd0-2d0e-4d4c-b974-86725a3386ad",
        "type": "message",
        "text": "Знакомый чел (<https:\/\/scholar.google.com\/citations?hl=en&amp;user=0hHqYoAAAAAJ&amp;view_op=list_works|scholar>) из Northeastern University (Boston)  ищет PhD студентов и попросил запостить.\n\nI am broadly interested in computer vision, natural language processing, and computational photography. Currently, there are three active research directions in my lab.\n\n• *Dynamic scene understanding and synthesis.* We live in a 3D visual world, which is constantly in motion. How to build a holistic 3D scene understanding model unifying appearance, geometry, motion, and semantics, to allow a machine to understand and re-create visual scenes more effectively?\n• *Compositional and multimodal visual reasoning.* We humans learn concepts in a compositional manner: an event consists of different actions, an action is composed of different objects, and an object can be decomposed into different parts. How can we teach machines to perform compositional reasoning, to allow learning from a few examples and better dealing with out-of-distribution test data? Visual reasoning is also multimodal. Kids, for instance, learn new concepts and knowledge from reading books with pictures and text. How can we teach machines to develop visual intelligence using natural language as a scaffold?\n• *Enhancing photography experiences in the mobile era.* Taking photos has never been so easy with smartphones. The latest smartphones are usually equipped with powerful computational resources, cameras, and sensors, such as LiDar and Dual Pixel, which provide us with great opportunities to improve usersâ€™ photography experiences of recording and sharing their daily lives in the mobile era.\nСсылка с деталями:\n<https:\/\/jianghz.me\/opportunities\/?fbclid=IwAR0f2tT56TfZwO02q387uF9xgW16LzBbgUN0N2r9ljSvBBrrmXxUKH5U0PU>",
        "user": "U065VPQMC",
        "ts": "1603295649.011100",
        "team": "T040HKJE3",
        "user_team": "T040HKJE3",
        "source_team": "T040HKJE3",
        "user_profile": {
            "avatar_hash": "8c7176d423bf",
            "image_72": "https:\/\/avatars.slack-edge.com\/2020-04-20\/1074583921091_8c7176d423bf388db2b1_72.jpg",
            "first_name": "Dmitry",
            "real_name": "Dmitry Petrov",
            "display_name": "dmitry_petrov",
            "team": "T040HKJE3",
            "name": "dmitry_petrov",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "edited": {
            "user": "U065VPQMC",
            "ts": "1603741048.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "mpW",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Знакомый чел ("
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/scholar.google.com\/citations?hl=en&user=0hHqYoAAAAAJ&view_op=list_works",
                                "text": "scholar"
                            },
                            {
                                "type": "text",
                                "text": ") из Northeastern University (Boston)  ищет PhD студентов и попросил запостить.\n\nI am broadly interested in computer vision, natural language processing, and computational photography. Currently, there are three active research directions in my lab.\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Dynamic scene understanding and synthesis.",
                                        "style": {
                                            "bold": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " We live in a 3D visual world, which is constantly in motion. How to build a holistic 3D scene understanding model unifying appearance, geometry, motion, and semantics, to allow a machine to understand and re-create visual scenes more effectively?"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Compositional and multimodal visual reasoning.",
                                        "style": {
                                            "bold": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " We humans learn concepts in a compositional manner: an event consists of different actions, an action is composed of different objects, and an object can be decomposed into different parts. How can we teach machines to perform compositional reasoning, to allow learning from a few examples and better dealing with out-of-distribution test data? Visual reasoning is also multimodal. Kids, for instance, learn new concepts and knowledge from reading books with pictures and text. How can we teach machines to develop visual intelligence using natural language as a scaffold?"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Enhancing photography experiences in the mobile era.",
                                        "style": {
                                            "bold": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " Taking photos has never been so easy with smartphones. The latest smartphones are usually equipped with powerful computational resources, cameras, and sensors, such as LiDar and Dual Pixel, which provide us with great opportunities to improve usersâ€™ photography experiences of recording and sharing their daily lives in the mobile era."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nСсылка с деталями:\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/jianghz.me\/opportunities\/?fbclid=IwAR0f2tT56TfZwO02q387uF9xgW16LzBbgUN0N2r9ljSvBBrrmXxUKH5U0PU"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UCNKBQJEN",
                    "ULRRFCUR0",
                    "U6QCY6ZAQ",
                    "U7WFH7UUF",
                    "U9JSUB8T1",
                    "UC7DFDJUA",
                    "U854H9KCM",
                    "U10P8BDU1",
                    "ULPRYQNS2",
                    "UKCLQLZB2",
                    "U0SBLSTJ4",
                    "U6FPTF7MW",
                    "UTSBPULD7",
                    "U049HDR2Z",
                    "U823FMJSV"
                ],
                "count": 15
            }
        ]
    }
]